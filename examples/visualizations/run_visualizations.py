# -*- coding: utf-8 -*-
"""Hands-on Language Change.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xFWgCToRzQ-Mf9YSLbVoI3wi2kMx_XZL
"""

#!pip install git+https://github.com/pierluigic/languagechange.git

"""# **DWUGs**

**English**
"""

import IPython
from languagechange.benchmark import DWUG
IPython.embed_kernel()

dwug_en = DWUG(language='EN',version='2.0.1')

dwug_en.show_usage_graph('plane_nn')

"""**Spanish**"""

from languagechange.benchmark import DWUG

dwug_es = DWUG(language='ES',version='4.0.0 (full)')

dwug_es.show_usage_graph('servidor')

"""**ESSLI**

Upload the ESSLI ZIP
"""

#!unzip WUG_ESSLI_Summer_School.zip -d WUG_ESSLI_Summer_School

"""# **Computational representation of lexical items**"""
import torch
from languagechange.models.representation.contextualized import XL_LEXEME

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = XL_LEXEME(device=device)

"""**Compute vectors for the word plane**


"""

from languagechange.benchmark import DWUG
import numpy as np

word = 'plane_nn'

usages_time1 = dwug_en.get_word_usages(word,group='1')
usages_time2 = dwug_en.get_word_usages(word,group='2')

vectors_time1 = model.encode(usages_time1)
vectors_time2 = model.encode(usages_time2)

print(vectors_time1.shape)
print(usages_time1[0])

"""**Compute vectors for the word graft and clustering usages**"""

from sklearn.cluster import AgglomerativeClustering
import numpy as np

word = 'graft_nn'

usages_time1 = dwug_en.get_word_usages(word,group='1')
usages_time2 = dwug_en.get_word_usages(word,group='2')

vectors_time1 = model.encode(usages_time1)
vectors_time2 = model.encode(usages_time2)

vectors = np.concatenate((vectors_timedevice1,vectors_time2),axis=0)

clustering=AgglomerativeClustering(n_clusters=None,linkage='average',metric='cosine',distance_threshold=0.5).fit(vectors)

"""**Visualization of the *graft* usages**"""

from matplotlib import pyplot as plt
from sklearn.manifold import TSNE
from matplotlib.lines import Line2D

clustering_labels = clustering.labels_
clustering_labels_T1 = clustering_labels[:len(vectors_time1)]
clustering_labels_T2 = clustering_labels[len(vectors_time1):]

reduced_vectors = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(vectors)
reduced_vectors_T1 = reduced_vectors[:len(vectors_time1)]
reduced_vectors_T2 = reduced_vectors[len(vectors_time1):]

markers = list(Line2D.markers.keys())

for j,label in enumerate(set(clustering_labels_T1)):
  cluster_vectors = reduced_vectors_T1[np.where(clustering_labels_T1 == label)[0]]
  X,Y = cluster_vectors[:,0], cluster_vectors[:,1]
  plt.scatter(X, Y, color='red', marker=markers[j], label=f'T1_{label}')

for j,label in enumerate(set(clustering_labels_T2)):
  cluster_vectors = reduced_vectors_T2[np.where(clustering_labels_T2 == label)[0]]
  X,Y = cluster_vectors[:,0], cluster_vectors[:,1]
  plt.scatter(X, Y, color='blue', marker=markers[j], label=f'T2_{label}')

plt.legend(numpoints=1)
plt.show()

"""**Inspecting the *graft* clusters**"""

from IPython.display import Markdown, display

def text_formatting(usage,time_label):
      start, end = usage.start(), usage.end()
      formatted_text = f'T{time_label}\t' + usage[:start] + '**' + usage[start:end] + '**' + usage[end:]
      return formatted_text

cluster2ids = {}
usages = usages_time1 + usages_time2
time_label = [1]*len(usages_time1) + [2]*len(usages_time2)

for i,label in enumerate(clustering.labels_):
  if not label in cluster2ids:
    cluster2ids[label] = []
  cluster2ids[label].append(i)


for c in sorted(cluster2ids):
  print(f'CLUSTER {c}')
  for idx in cluster2ids[c][:10]:
    display(Markdown(text_formatting(usages[idx], time_label[idx])))
  print('----------------------------')

"""# **Lexical Semantic Change Metrics**

**Average Pairwise Distance**
"""

from languagechange.models.change.metrics import APD, PRT, PJSD

word = 'plane_nn'

usages_time1 = dwug_en.get_word_usages(word,group='1')
usages_time2 = dwug_en.get_word_usages(word,group='2')

vectors_time1 = model.encode(usages_time1)
vectors_time2 = model.encode(usages_time2)

apd_metric = APD()

apd_metric.compute_scores(vectors_time1,vectors_time2)

"""**Prototype Distance**"""

from languagechange.models.change.metrics import APD, PRT, PJSD

word = 'plane_nn'

usages_time1 = dwug_en.get_word_usages(word,group='1')
usages_time2 = dwug_en.get_word_usages(word,group='2')

vectors_time1 = model.encode(usages_time1)
vectors_time2 = model.encode(usages_time2)

prt_metric = PRT()

prt_metric.compute_scores(vectors_time1,vectors_time2)

"""**Probabilities Jensen-Shannon Distance**"""

from languagechange.models.change.metrics import APD, PRT, PJSD

word = 'plane_nn'

usages_time1 = dwug_en.get_word_usages(word,group='1')
usages_time2 = dwug_en.get_word_usages(word,group='2')

vectors_time1 = model.encode(usages_time1)
vectors_time2 = model.encode(usages_time2)

clustering=AgglomerativeClustering(n_clusters=None,linkage='average',metric='cosine',distance_threshold=0.5)
pjsd_metric = PJSD()

pjsd_metric.compute_scores(vectors_time1,vectors_time2,clustering)

